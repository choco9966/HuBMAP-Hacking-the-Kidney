{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-09T09:48:27.002572Z",
     "iopub.status.busy": "2021-04-09T09:48:27.001552Z",
     "iopub.status.idle": "2021-04-09T09:50:32.737222Z",
     "shell.execute_reply": "2021-04-09T09:50:32.736490Z"
    },
    "papermill": {
     "duration": 125.765547,
     "end_time": "2021-04-09T09:50:32.737375",
     "exception": false,
     "start_time": "2021-04-09T09:48:26.971828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/segmentation-models-pytorch-0-1-3/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (1.7.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (0.8.1)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (2.5.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (4.45.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4) (1.14.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (3.7.4.1)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (1.18.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (1.18.5)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (1.7.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (8.0.1)\r\n",
      "Building wheels for collected packages: pretrainedmodels\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=3445d64b7e650b144b6526ee14c77f4ad98f962c03ff1c0efd76480645c9dfba\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/1d/68/a396f54fb35d35ad4306a9bdefb38c539e52caeeab04265592\r\n",
      "Successfully built pretrainedmodels\r\n",
      "Installing collected packages: pretrainedmodels\r\n",
      "Successfully installed pretrainedmodels-0.7.4\r\n",
      "Processing /kaggle/input/segmentation-models-pytorch-0-1-3/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3) (1.7.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (3.7.4.1)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (1.18.5)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12419 sha256=7b5058f9257f924f4402a3191b5e3553ca399068b6f02a493689a5a9336d8515\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/3b/8b/6261d7cfbc856fb679256e9cac397bbebf778e9a7790935d14\r\n",
      "Successfully built efficientnet-pytorch\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.6.3\r\n",
      "Processing /kaggle/input/segmentation-models-pytorch-0-1-3/timm-0.3.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm==0.3.2) (1.7.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.3.2) (0.8.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.3.2) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.3.2) (3.7.4.1)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.3.2) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.3.2) (1.18.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.3.2) (1.18.5)\r\n",
      "Requirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm==0.3.2) (1.7.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.3.2) (8.0.1)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.3.2\r\n",
      "Processing /kaggle/input/segmentation-models-pytorch-0-1-3/segmentation_models.pytorch.0.1.3/segmentation_models.pytorch.0.1.3\r\n",
      "Requirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.3) (0.8.1)\r\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.3) (0.7.4)\r\n",
      "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.3) (0.6.3)\r\n",
      "Requirement already satisfied: timm==0.3.2 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.3) (0.3.2)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (1.7.0)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.3) (2.5.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (1.7.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.3) (4.45.0)\r\n",
      "Requirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.3) (0.8.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.3) (1.14.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (1.7.0)\r\n",
      "Requirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.3) (0.8.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (3.7.4.1)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (1.18.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (1.18.5)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.3) (1.7.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.3.0->segmentation-models-pytorch==0.1.3) (8.0.1)\r\n",
      "Building wheels for collected packages: segmentation-models-pytorch\r\n",
      "  Building wheel for segmentation-models-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for segmentation-models-pytorch: filename=segmentation_models_pytorch-0.1.3-py3-none-any.whl size=83181 sha256=12fa3f6b9e637b875b802b946f2861f5a17a3663d928858047a5c44569454d80\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kqthogh3/wheels/7f/aa/84/fce659a775026707381758fc327138ecf79061abe4fec7f221\r\n",
      "Successfully built segmentation-models-pytorch\r\n",
      "Installing collected packages: segmentation-models-pytorch\r\n",
      "Successfully installed segmentation-models-pytorch-0.1.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/segmentation-models-pytorch-0-1-3/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\n",
    "!pip install ../input/segmentation-models-pytorch-0-1-3/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\n",
    "!pip install ../input/segmentation-models-pytorch-0-1-3/timm-0.3.2-py3-none-any.whl\n",
    "!pip install ../input/segmentation-models-pytorch-0-1-3/segmentation_models.pytorch.0.1.3/segmentation_models.pytorch.0.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:32.827020Z",
     "iopub.status.busy": "2021-04-09T09:50:32.825871Z",
     "iopub.status.idle": "2021-04-09T09:50:38.901459Z",
     "shell.execute_reply": "2021-04-09T09:50:38.900783Z"
    },
    "papermill": {
     "duration": 6.13928,
     "end_time": "2021-04-09T09:50:38.901595",
     "exception": false,
     "start_time": "2021-04-09T09:50:32.762315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import pdb\n",
    "import glob\n",
    "import pytz\n",
    "import warnings\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import tifffile as tiff\n",
    "import rasterio\n",
    "from rasterio.windows import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:38.949013Z",
     "iopub.status.busy": "2021-04-09T09:50:38.946458Z",
     "iopub.status.idle": "2021-04-09T09:50:38.949776Z",
     "shell.execute_reply": "2021-04-09T09:50:38.950339Z"
    },
    "papermill": {
     "duration": 0.028696,
     "end_time": "2021-04-09T09:50:38.950477",
     "exception": false,
     "start_time": "2021-04-09T09:50:38.921781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose,\n",
    "    CenterCrop,\n",
    "    CLAHE,\n",
    "    Resize,\n",
    "    Normalize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:39.000903Z",
     "iopub.status.busy": "2021-04-09T09:50:39.000175Z",
     "iopub.status.idle": "2021-04-09T09:50:39.753905Z",
     "shell.execute_reply": "2021-04-09T09:50:39.753036Z"
    },
    "papermill": {
     "duration": 0.783833,
     "end_time": "2021-04-09T09:50:39.754113",
     "exception": false,
     "start_time": "2021-04-09T09:50:38.970280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epoch: 4, loss: 0.0265, dice: 0.9112 \n",
    "height, width = 1024, 1024\n",
    "reduce = 2\n",
    "THRESHOLD = 0.4\n",
    "window = 2048\n",
    "min_overlap = 256\n",
    "DATA = '../input/hubmap-kidney-segmentation/test/'\n",
    "MODELS = [\"../input/humapscoretest/FOLD-0-effb4_img512_bs32_nm.pth\"]\n",
    "df_sample = pd.read_csv('../input/hubmap-kidney-segmentation/sample_submission.csv')\n",
    "batch_size = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021112,
     "end_time": "2021-04-09T09:50:39.811575",
     "exception": false,
     "start_time": "2021-04-09T09:50:39.790463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Mask to Rle and Rle to Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:39.875381Z",
     "iopub.status.busy": "2021-04-09T09:50:39.872376Z",
     "iopub.status.idle": "2021-04-09T09:50:39.876574Z",
     "shell.execute_reply": "2021-04-09T09:50:39.877415Z"
    },
    "papermill": {
     "duration": 0.044935,
     "end_time": "2021-04-09T09:50:39.877561",
     "exception": false,
     "start_time": "2021-04-09T09:50:39.832626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#functions to convert encoding to mask and mask to encoding\n",
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for m,enc in enumerate(encs):\n",
    "        if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2enc(mask, n=1):\n",
    "    pixels = mask.T.flatten()\n",
    "    encs = []\n",
    "    for i in range(1,n+1):\n",
    "        p = (pixels == i).astype(np.int8)\n",
    "        if p.sum() == 0: encs.append(np.nan)\n",
    "        else:\n",
    "            p = np.concatenate([[0], p, [0]])\n",
    "            runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "            runs[1::2] -= runs[::2]\n",
    "            encs.append(' '.join(str(x) for x in runs))\n",
    "    return encs\n",
    "\n",
    "#https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n",
    "#with transposed mask\n",
    "def rle_encode_less_memory(img):\n",
    "    #the image should be transposed\n",
    "    pixels = img.T.flatten()\n",
    "    \n",
    "    # This simplified method requires first and last pixel to be zero\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    \n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:39.944931Z",
     "iopub.status.busy": "2021-04-09T09:50:39.943763Z",
     "iopub.status.idle": "2021-04-09T09:50:39.952956Z",
     "shell.execute_reply": "2021-04-09T09:50:39.952362Z"
    },
    "papermill": {
     "duration": 0.05359,
     "end_time": "2021-04-09T09:50:39.953066",
     "exception": false,
     "start_time": "2021-04-09T09:50:39.899476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imagenet statistics Mean and variance\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "\n",
    "def get_transforms(mean, std):\n",
    "    list_transforms = [Resize(height=height, width=width, interpolation=cv2.INTER_AREA, p=1.0)]\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Normalize(mean=mean, std=std, p=1.0),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def make_grid(shape, window=256, min_overlap=32):\n",
    "    \"\"\"\n",
    "        Return Array of size (N,4), where N - number of tiles,\n",
    "        2nd axis represente slices: x1,x2,y1,y2 \n",
    "    \"\"\"\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n",
    "    \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n",
    "    return slices.reshape(nx*ny,4)\n",
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        if self.data.count != 3:\n",
    "            subdatasets = self.data.subdatasets\n",
    "            self.layers = []\n",
    "            if len(subdatasets) > 0:\n",
    "                for i, subdataset in enumerate(subdatasets, 0):\n",
    "                    self.layers.append(rasterio.open(subdataset))\n",
    "        self.shape = self.data.shape\n",
    "        self.mask_grid = make_grid(self.data.shape, window=window, min_overlap=min_overlap)\n",
    "        self.transforms = get_transforms(mean, std)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mask_grid)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x1, x2, y1, y2 = self.mask_grid[idx]\n",
    "        if self.data.count == 3:\n",
    "            img = data.read([1,2,3], window=Window.from_slices((x1, x2), (y1, y2)))\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        else:\n",
    "            img = np.zeros((window, window, 3), dtype=np.uint8)\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                img[:,:,i] = layer.read(window=Window.from_slices((x1,x2),(y1,y2)))\n",
    "        augmented = self.transforms(image=img)\n",
    "        img = augmented['image']\n",
    "        vetices = torch.tensor([x1, x2, y1, y2])\n",
    "        return img, vetices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0201,
     "end_time": "2021-04-09T09:50:39.993635",
     "exception": false,
     "start_time": "2021-04-09T09:50:39.973535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize models and load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:40.047423Z",
     "iopub.status.busy": "2021-04-09T09:50:40.046563Z",
     "iopub.status.idle": "2021-04-09T09:50:47.242419Z",
     "shell.execute_reply": "2021-04-09T09:50:47.243062Z"
    },
    "papermill": {
     "duration": 7.227227,
     "end_time": "2021-04-09T09:50:47.243212",
     "exception": false,
     "start_time": "2021-04-09T09:50:40.015985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for path in MODELS:\n",
    "    state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model = smp.Unet('timm-efficientnet-b4', classes=1, encoder_weights=None)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "del state_dict\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:47.299181Z",
     "iopub.status.busy": "2021-04-09T09:50:47.296744Z",
     "iopub.status.idle": "2021-04-09T09:50:47.299959Z",
     "shell.execute_reply": "2021-04-09T09:50:47.300585Z"
    },
    "papermill": {
     "duration": 0.036541,
     "end_time": "2021-04-09T09:50:47.300777",
     "exception": false,
     "start_time": "2021-04-09T09:50:47.264236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Make_prediction(img, tta = True):\n",
    "    pred = None\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            p_tta = None\n",
    "            p = model(img)\n",
    "            p = torch.sigmoid(p).detach()\n",
    "            if p_tta is None:\n",
    "                p_tta = p\n",
    "            else:\n",
    "                p_tta += p\n",
    "            if tta:\n",
    "                #x,y,xy flips as TTA\n",
    "                flips = [[-1],[-2],[-2,-1]]\n",
    "                for f in flips:\n",
    "                    imgf = torch.flip(img, f)\n",
    "                    p = model(imgf)\n",
    "                    p = torch.flip(p, f)\n",
    "                    p_tta += torch.sigmoid(p).detach()\n",
    "                p_tta /= (1+len(flips))\n",
    "            if pred is None:\n",
    "                pred = p_tta\n",
    "            else:\n",
    "                pred += p_tta\n",
    "        pred /= len(models)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:50:47.358723Z",
     "iopub.status.busy": "2021-04-09T09:50:47.357564Z",
     "iopub.status.idle": "2021-04-09T09:59:02.364296Z",
     "shell.execute_reply": "2021-04-09T09:59:02.360044Z"
    },
    "papermill": {
     "duration": 495.042694,
     "end_time": "2021-04-09T09:59:02.364488",
     "exception": false,
     "start_time": "2021-04-09T09:50:47.321794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3da0492084f493492d034ff2b5463a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/rasterio/__init__.py:221: NotGeoreferencedWarning: Dataset has no geotransform set. The identity matrix may be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "names, predictions = [],[]\n",
    "for idx, row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n",
    "    imageId = row['id']\n",
    "    data = rasterio.open(os.path.join(DATA, imageId+'.tiff'), transform = identity, num_threads='all_cpus')\n",
    "    preds = np.zeros(data.shape, dtype=np.uint8)\n",
    "    dataset = HuBMAPDataset(data)\n",
    "    dataloader = DataLoader(dataset, batch_size, num_workers=0, shuffle=False, pin_memory=True)\n",
    "    for i, (img, vertices) in enumerate(dataloader):\n",
    "        # img = torch.true_divide(img, 255)\n",
    "        img = img.to(device)\n",
    "        pred = Make_prediction(img, tta = False)\n",
    "        pred = pred.squeeze().cpu().numpy()\n",
    "        vertices = vertices.numpy()\n",
    "        for p, vert in zip(pred, vertices):\n",
    "            x1, x2, y1, y2 = vert\n",
    "            p = cv2.resize(p, (window, window))\n",
    "            preds[x1:x2,y1:y2] += (p > THRESHOLD).astype(np.uint8)\n",
    "            \n",
    "    preds = (preds > 0.5).astype(np.uint8)\n",
    "    #convert to rle\n",
    "    rle = rle_encode_less_memory(preds)\n",
    "    names.append(imageId)\n",
    "    predictions.append(rle)\n",
    "    \n",
    "    # break\n",
    "    del preds, dataset, dataloader\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:59:02.416834Z",
     "iopub.status.busy": "2021-04-09T09:59:02.415718Z",
     "iopub.status.idle": "2021-04-09T09:59:02.900280Z",
     "shell.execute_reply": "2021-04-09T09:59:02.899076Z"
    },
    "papermill": {
     "duration": 0.512354,
     "end_time": "2021-04-09T09:59:02.900422",
     "exception": false,
     "start_time": "2021-04-09T09:59:02.388068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':names,'predicted':predictions})\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T09:59:02.967787Z",
     "iopub.status.busy": "2021-04-09T09:59:02.966911Z",
     "iopub.status.idle": "2021-04-09T09:59:02.985293Z",
     "shell.execute_reply": "2021-04-09T09:59:02.984664Z"
    },
    "papermill": {
     "duration": 0.061668,
     "end_time": "2021-04-09T09:59:02.985414",
     "exception": false,
     "start_time": "2021-04-09T09:59:02.923746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ec3f1bb9</td>\n",
       "      <td>60714320 2 60738310 10 60762293 24 60762321 3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3589adb90</td>\n",
       "      <td>68423546 3 68423555 4 68452965 11 68452977 7 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d488c759a</td>\n",
       "      <td>456855934 5 456902593 10 456949251 16 45699591...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa05346ff</td>\n",
       "      <td>52948859 11 52979575 18 53010289 29 53041000 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57512b7f1</td>\n",
       "      <td>287069623 4 287102862 8 287136103 8 287169342 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          predicted\n",
       "0  2ec3f1bb9  60714320 2 60738310 10 60762293 24 60762321 3 ...\n",
       "1  3589adb90  68423546 3 68423555 4 68452965 11 68452977 7 6...\n",
       "2  d488c759a  456855934 5 456902593 10 456949251 16 45699591...\n",
       "3  aa05346ff  52948859 11 52979575 18 53010289 29 53041000 4...\n",
       "4  57512b7f1  287069623 4 287102862 8 287136103 8 287169342 ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 642.294671,
   "end_time": "2021-04-09T09:59:04.531413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-09T09:48:22.236742",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2a143da241e649428b8c334771bf4b99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "701d94f2222c4c2fa64c3e5742e6ea57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e9d628a26df546409200f3e1d5bad12b",
       "max": 5.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e8f2a2b93dab467fbc160a5e384f7cf2",
       "value": 5.0
      }
     },
     "8a4ef6963a5f481ebbe3146fab74202b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d3da0492084f493492d034ff2b5463a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_701d94f2222c4c2fa64c3e5742e6ea57",
        "IPY_MODEL_d9cc07847ef546cba7860c4972edf0b5"
       ],
       "layout": "IPY_MODEL_2a143da241e649428b8c334771bf4b99"
      }
     },
     "d419cbbc65144f43b32ee4055283dc05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9cc07847ef546cba7860c4972edf0b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d419cbbc65144f43b32ee4055283dc05",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8a4ef6963a5f481ebbe3146fab74202b",
       "value": " 5/5 [08:14&lt;00:00, 98.99s/it]"
      }
     },
     "e8f2a2b93dab467fbc160a5e384f7cf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e9d628a26df546409200f3e1d5bad12b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
